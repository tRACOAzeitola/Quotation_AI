# Cota√ß√µes AI: Assistente Inteligente para Cota√ß√µes de Frete

![Python](https://img.shields.io/badge/Python-3.13-blue?style=for-the-badge&logo=python)
![Redis](https://img.shields.io/badge/Redis-7.0-red?style=for-the-badge&logo=redis)
![Ollama](https://img.shields.io/badge/Ollama-Llama3-lightgrey?style=for-the-badge&logo=ollama)
![License](https://img.shields.io/badge/License-MIT-green?style=for-the-badge)

**Cota√ß√µes AI** √© um sistema automatizado para processar pedidos de cota√ß√£o de frete recebidos por e-mail. Utilizando um modelo de linguagem local (LLM) para interpreta√ß√£o de texto e uma arquitetura de filas para processamento ass√≠ncrono, o sistema oferece uma solu√ß√£o eficiente, privada e escal√°vel.

---

## üèõÔ∏è Arquitetura e Fluxo de Trabalho

O sistema adota o padr√£o **Produtor/Consumidor** para garantir desacoplamento e escalabilidade. O fluxo de trabalho √© o seguinte:

```mermaid
graph TD
    A -->|üìß E-mail Recebido| B{main.py (Produtor)}
    B --> |Enfileira Tarefa| C[üîÑ Redis (Fila de Tarefas)]
    C --> |Consome Tarefa| D[üë∑ rq worker (Consumidor)]
    D --> E(1. An√°lise com IA)
    E --> F(2. C√°lculo de Cota√ß√£o)
    F --> G(3. Envio de Resposta)
    G --> H[‚úÖ E-mail Enviado ao Cliente]
```

1.  **Produtor (`main.py`)**: Monitoriza a caixa de entrada, identifica e-mails de cota√ß√£o e enfileira uma tarefa no Redis para cada um.
2.  **Fila (Redis)**: Atua como *message broker*, armazenando as tarefas de forma persistente.
3.  **Consumidor (`rq worker`)**: Processa as tarefas da fila, orquestrando a an√°lise do e-mail, o c√°lculo da cota√ß√£o e o envio da resposta.

---

## ‚ú® Funcionalidades Principais

- **Processamento Ass√≠ncrono**: Utiliza **Redis** e **RQ (Redis Queue)** para gerir tarefas em segundo plano, permitindo que o sistema processe m√∫ltiplos e-mails em paralelo.
- **IA Local e Privada**: Emprega o **Ollama** para executar o modelo **Llama 3** localmente, garantindo que os dados dos e-mails nunca saiam da sua infraestrutura.
- **Extra√ß√£o e Normaliza√ß√£o Robusta de Dados**: Utiliza um LLM para extrair dados brutos (destino, peso, volume, tipo de transporte, temperatura) e fun√ß√µes Python para:
  -  **Normaliza√ß√£o de Peso e Volume (melhorada)**: Converte formatos variados para unidades padr√£o (kg e m¬≥), incluindo:
     - Volumes diretos: "45 m3", "0,42 m¬≥", "0.42 m^3".
     - Dimens√µes: "112x47x80 cm", "3 x 3 x 5 m", mistos como "3m x 3 x 5m".
     - Tratamento correto de unidades finais com espa√ßo (ex.: "... 80 cm" aplica-se √†s 3 dimens√µes).
  -  **Destino (agora sem fuzzy matching)**: O destino extra√≠do √© mantido exatamente como no e-mail (apenas normalizado para min√∫sculas). H√° uma regra expl√≠cita para mapear "Aeroporto de Lisboa/Lisboa Aeroporto" para "Lisboa". Caso n√£o exista correspond√™ncia exata na tabela de pre√ßos, a l√≥gica de fallback acontece no `cotador.py` via API (ver abaixo).
- **C√°lculo Otimizado**: Consulta uma tabela de pre√ßos em CSV (`tabela_precos.csv`) para encontrar a tarifa mais econ√≥mica que corresponda aos requisitos do pedido.
- **Fallback por Dist√¢ncia (Novo)**: Se n√£o houver entrada exata na tabela para o destino, o sistema usa geocoding do destino e dist√¢ncia de condu√ß√£o a partir de "Lisboa, Portugal" e calcula o pre√ßo por km (detalhes na se√ß√£o abaixo).
- **Respostas Autom√°ticas**: Envia um e-mail de resposta profissional, formatado em HTML, com os detalhes da cota√ß√£o.
- **Logging Detalhado**: Regista todas as opera√ß√µes e erros em `app.log` para f√°cil monitoriza√ß√£o e depura√ß√£o, com a op√ß√£o de ativar n√≠vel `DEBUG` para depura√ß√£o profunda.
- **RAG Local (Opcional)**: Integra√ß√£o com **ChromaDB + LlamaIndex** para consulta de exemplos internos (e-mails/cota√ß√µes anteriores) e melhoria de extra√ß√µes. Persist√™ncia em `./rag_test_db`. Embeddings for√ßados a **CPU**. Se as depend√™ncias n√£o estiverem dispon√≠veis, existe fallback autom√°tico para um modo em mem√≥ria (sem fuzzy matching), mantendo a mesma API.

---

## üõ†Ô∏è Tecnologias Utilizadas

- **Linguagem**: Python 3.13
- **IA e LLM**: Ollama (com Llama 3)
- **Fila de Mensagens**: Redis, RQ (Redis Queue)
- **Manipula√ß√£o de Dados**: Pandas
- **Gest√£o de Depend√™ncias**: Pip, `requirements.txt`
- **Vari√°veis de Ambiente**: `python-dotenv`
- **RAG**: ChromaDB (persistente local) + LlamaIndex (camada de indexa√ß√£o/consulta) + Sentence-Transformers (embeddings locais) [opcional, com fallback em mem√≥ria]
- **Fallback de dist√¢ncia**: Nominatim (Geocoding via HTTP) + OSRM (Driving distance) via `requests` (sem chave de API)

---

## üöÄ Guia de Instala√ß√£o e Execu√ß√£o

Siga estes passos para configurar e executar o projeto.

### 1. Pr√©-requisitos

- Python 3.8 ou superior
- Git
- **Redis**: A correr localmente. [Ver op√ß√µes de instala√ß√£o](#3-configura√ß√£o-do-redis).
- **Ollama**: Instalado e em execu√ß√£o. Visite [ollama.com](https://ollama.com/) para descarregar.

### 2. Instala√ß√£o do Projeto

```bash
# 1. Clone o reposit√≥rio
git clone <URL_DO_REPOSITORIO>
cd Cota√ßoes_AI

# 2. Crie e ative um ambiente virtual
python3 -m venv venv
source venv/bin/activate
# No Windows: venv\Scripts\activate

# 3. Instale as depend√™ncias m√≠nimas
pip install -r requirements.txt

# 4. Descarregue o modelo de IA (com o Ollama a correr)
ollama pull llama3
```

Observa√ß√µes:
- O RAG completo (ChromaDB/LlamaIndex + embeddings) √© opcional. Caso n√£o o instale, o sistema usa um fallback em mem√≥ria para a parte de similaridade.
- Para instalar o RAG completo em Python 3.13 (CPU), pode usar:

```bash
# PyTorch (CPU wheels)
pip install -U torch --index-url https://download.pytorch.org/whl/cpu

# Transformers + Sentence-Transformers
pip install -U transformers
pip install -U sentence-transformers

# ChromaDB e LlamaIndex
pip install -U chromadb
pip install -U llama-index llama-index-vector-stores-chroma llama-index-embeddings-huggingface
```

### 3. Configura√ß√£o do Redis

- **Docker (Recomendado)**:
  ```bash
  docker run -d -p 6379:6379 --name cotacoes-redis redis
  ```
- **Homebrew (macOS)**:
  ```bash
  brew install redis && brew services start redis
  ```

### 4. Vari√°veis de Ambiente

Crie um ficheiro `.env` a partir do exemplo e preencha as suas credenciais.

```bash
cp .env.example .env
```

- `EMAIL_USUARIO`: O e-mail que o sistema usar√°.
- `EMAIL_SENHA`: **Senha de aplica√ß√£o** do e-mail (para o Gmail, n√£o use a senha principal).
- `EMAIL_SERVIDOR`: Servidor IMAP (ex: `imap.gmail.com`).
- `SMTP_SERVIDOR`: Servidor SMTP (ex: `smtp.gmail.com`).

### 5. Tabela de Pre√ßos

Por motivos de privacidade, a tabela de pre√ßos n√£o √© partilhada no reposit√≥rio. Crie a sua a partir do ficheiro de exemplo:

```bash
cp tabela_precos.example.csv tabela_precos.csv
```

Depois, edite `tabela_precos.csv` com as suas pr√≥prias tarifas.

### 6. Execu√ß√£o

Abra **dois terminais** no diret√≥rio do projeto.

- **Terminal 1: Inicie o Worker**
  ```bash
  # Ative o ambiente virtual: source venv/bin/activate
  # macOS (recomendado para evitar crashes do Metal/MPS em processos forkados)
  export OBJC_DISABLE_INITIALIZE_FORK_SAFETY=YES
  export PYTORCH_ENABLE_MPS_FALLBACK=1
  export CUDA_VISIBLE_DEVICES=""
  rq worker
  ```

- **Terminal 2: Execute o Produtor**
  ```bash
  # Ative o ambiente virtual: source venv/bin/activate
  python3 main.py
```

O produtor ir√° ler os e-mails e enfileirar as tarefas, que ser√£o processadas pelo worker.

#### Execu√ß√£o do pipeline RAG (Demo Local)

Para experimentar a base vetorial local com exemplos fict√≠cios:

```bash
python3 rag_pipeline_test.py
```

Este script ir√°:
- Persistir documentos de exemplo no `./rag_test_db`
- Executar consultas e imprimir os resultados mais relevantes

### 7. Modo de Teste (Simula√ß√£o de E-mails)

Para testar o fluxo completo sem interagir com servidores de e-mail reais (IMAP/SMTP) ou a necessidade de e-mails em tempo real, pode ativar o `APP_TEST_MODE`.

1.  **Modificar `email_reader.py`**: A fun√ß√£o `obter_emails()` retornar√° um e-mail de teste hardcoded.
2.  **Modificar `email_sender.py`**: A fun√ß√£o `enviar_email_cotacao()` registar√° o HTML completo do e-mail de resposta no log, em vez de envi√°-lo.

Para executar no modo de teste, abra **dois terminais** no diret√≥rio do projeto e, em AMBOS os terminais, antes de ativar o ambiente virtual, defina a vari√°vel de ambiente:

```bash
export APP_TEST_MODE=true
# Para macOS, no terminal do worker, adicione tamb√©m:
# export OBJC_DISABLE_INITIALIZE_FORK_SAFETY=YES
```

Depois, siga os passos de `6. Execu√ß√£o` acima. No log do `rq worker`, procure por `HTML gerado (simulado):` para ver o conte√∫do HTML da resposta do e-mail.

**Dica de Depura√ß√£o**: Para ver logs mais detalhados, incluindo o processo de normaliza√ß√£o e fuzzy matching, pode alterar o n√≠vel do logger para `DEBUG` em `logger_config.py` (linha `9`):

```python
# logger_config.py
logger.setLevel(logging.DEBUG)
```

---

## üîç RAG Local (ChromaDB + LlamaIndex)

Esta integra√ß√£o permite que o sistema consulte exemplos anteriores para dar contexto ao LLM e melhorar a extra√ß√£o (especialmente em destinos amb√≠guos como aeroportos ou regi√µes pr√≥ximas).

- **Persist√™ncia**: `./rag_test_db` (pasta local)
- **Embeddings**: `sentence-transformers/all-MiniLM-L6-v2` (100% local), executados em **CPU** para maior compatibilidade.
- **M√≥dulo**: `rag_store.py`
  - `ingest_email(email_text: str, metadata: dict) -> str`
  - `retrieve_similar(query_text: str, top_k: int = 3) -> list[dict]`
- **Demo/seed**: `rag_pipeline_test.py`
- **Testes**: `tests/test_rag_pipeline.py`

### Como o RAG √© usado no pipeline real

- `agent.py/analisar_email()`
  - Recupera contexto via `retrieve_similar(corpo_email, top_k=3)`
  - Injeta esse contexto no prompt do LLM (Ollama/Llama3) antes da extra√ß√£o

- `tasks.py/processar_email_task()`
  - Ap√≥s envio do e-mail com sucesso, persiste o exemplo no vector store via `ingest_email()` com metadados √∫teis (`destino`, `peso`, `volume`, `temperatura`, `tipo_transporte`)

### Vari√°veis de ambiente (sugest√£o)

Opcionalmente, pode controlar o uso do RAG com uma flag (ainda n√£o obrigat√≥ria):

```
RAG_ENABLED=true
```

Se desativado ou se as depend√™ncias n√£o estiverem instaladas, o m√≥dulo `rag_store.py` ativa automaticamente um fallback em mem√≥ria que mant√©m a mesma API (similaridade simples por sobreposi√ß√£o de palavras).

---

## üöö Fallback de Pre√ßo por Dist√¢ncia (Nominatim + OSRM)

Quando o destino extra√≠do n√£o existir exatamente na `tabela_precos.csv`, o `cotador.py` executa o seguinte:

- Geocoding do destino e da origem fixa "Lisboa, Portugal" usando Nominatim via HTTP.
- C√°lculo da dist√¢ncia de condu√ß√£o usando o endpoint p√∫blico do OSRM.
- C√°lculo do pre√ßo por km com base em faixas configur√°veis em ficheiro privado.

Requisitos: apenas `requests`. N√£o √© necess√°ria chave de API. O pedido inclui um header `User-Agent` conforme recomendado pelo Nominatim.

### Configura√ß√£o Privada de Pre√ßos por Km

Os valores das faixas s√£o confidenciais e n√£o devem ser commitados no reposit√≥rio. Use um ficheiro gitignored `pricing_config.json` com a seguinte estrutura:

```json
[
  {
    "peso_max": 500,
    "volume_max": 2,
    "tarifa_eur_km": 0.0,
    "tipo_transporte": "carro (<500Kg/<2M3)"
  }
  // ... adicione as restantes faixas
]
```

Passos recomendados:
- Copie o exemplo e preencha com os valores reais (n√£o commit):
  ```bash
  cp pricing_config.example.json pricing_config.json
  ```
- Opcionalmente, aponte para outro caminho via vari√°vel de ambiente `PRICING_CONFIG_PATH`.

## üóÇÔ∏è Estrutura da Tabela de Pre√ßos

O ficheiro `tabela_precos.csv` √© o cora√ß√£o da l√≥gica de cota√ß√£o. A sua estrutura deve ser a seguinte:

| Coluna          | Descri√ß√£o                                         | Exemplo         |
|-----------------|---------------------------------------------------|-----------------|
| `destino`       | Localidade de entrega (min√∫sculas)                | `lisboa`        |
| `peso_maximo`   | Peso m√°ximo (kg) suportado por esta tarifa        | `1000`          |
| `volume_maximo` | Volume m√°ximo (m¬≥) suportado                      | `10`            |
| `tipo_transporte` | Descri√ß√£o do servi√ßo                              | `Normal`        |
| `temperatura`   | Condi√ß√£o de transporte (`ambiente` ou `frio`)     | `ambiente`      |
| `preco`         | Custo final do servi√ßo em euros                   | `150.50`        |

---

## üß∞ Troubleshooting

- **macOS: Crash envolvendo Metal/MPS (MPSLibrary ... XPC_ERROR_CONNECTION_INVALID)**
  - Execute o worker com:
    ```bash
    export OBJC_DISABLE_INITIALIZE_FORK_SAFETY=YES
    export PYTORCH_ENABLE_MPS_FALLBACK=1
    export CUDA_VISIBLE_DEVICES=""
    rq worker
    ```
  - Os embeddings do RAG est√£o for√ßados a CPU no c√≥digo (`rag_store.py`).

- **ImportError: No module named 'chromadb' durante testes**
  - O RAG √© opcional. Se n√£o quiser instalar o stack completo, o sistema usa fallback em mem√≥ria automaticamente.
  - Para instalar o stack completo no Python 3.13 (CPU), siga os comandos da sec√ß√£o de instala√ß√£o (PyTorch CPU, transformers/sentence-transformers, ChromaDB, LlamaIndex).

- **Geocoding/OSRM**
  - Nominatim √© rate-limited. Para uso intensivo, considere cachear resultados ou self-hosting.
  - O OSRM p√∫blico √© best-effort. Para produ√ß√£o, considere self-hosting um servidor OSRM.


## üìú Licen√ßa

Este projeto est√° licenciado sob a Licen√ßa MIT. Consulte o ficheiro `LICENSE` para mais detalhes.